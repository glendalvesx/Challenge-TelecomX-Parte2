{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mVTWN9LYUIP",
        "outputId": "d296501f-8995-4f7a-d4b0-e505263d1945"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.3)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.12/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install pandas requests seaborn matplotlib scikit-learn imbalanced-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "z6Ju4aySYUIQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn.impute import SimpleImputer\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "C0NMHxZcYUIR",
        "outputId": "60872ae0-3a8a-4ca5-f47e-f68c1c00464a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'TelecomX_Dados_Tratados.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4189299625.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0marquivo_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"TelecomX_Dados_Tratados.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataclean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marquivo_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'TelecomX_Dados_Tratados.csv'"
          ]
        }
      ],
      "source": [
        "arquivo_csv = \"TelecomX_Dados_Tratados.csv\"\n",
        "dataclean = pd.read_csv(arquivo_csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFlSMgiqYUIR"
      },
      "outputs": [],
      "source": [
        "dataclean = dataclean.drop(columns=['customerID'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1_nseHNYUIR"
      },
      "outputs": [],
      "source": [
        "boolean_cols = ['Idoso', 'Parceiro', 'Dependentes', 'Servico_Celular',\n",
        "                'Linhas_Adicionais', 'Servico_Internet', 'Seguranca_Online',\n",
        "                'Backup_Online', 'Protecao_Dispositivo', 'Suporte_Tecnico',\n",
        "                'TV_Streaming', 'Filmes_Streaming', 'Faturamento_Sem_Papel']\n",
        "for col in boolean_cols:\n",
        "    dataclean[col] = dataclean[col].map({'Sim': 1, 'Nao': 0})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DSFo6x8YUIR"
      },
      "outputs": [],
      "source": [
        "categorical_cols = ['Genero', 'Contrato', 'Metodo_de_Pagamento']\n",
        "dataclean = pd.get_dummies(dataclean, columns=categorical_cols, drop_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GeZscWDcYUIS"
      },
      "outputs": [],
      "source": [
        "num_cols = ['Meses_Cliente', 'Faturamento_Mensal', 'Faturamento_Total', 'Contas_Diarias']\n",
        "for col in num_cols:\n",
        "    dataclean[col] = pd.to_numeric(dataclean[col], errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWhoTpInYUIS"
      },
      "outputs": [],
      "source": [
        "imputer_num = SimpleImputer(strategy='median')\n",
        "dataclean[num_cols] = imputer_num.fit_transform(dataclean[num_cols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roNxHPCeYUIS"
      },
      "outputs": [],
      "source": [
        "dataclean[boolean_cols] = dataclean[boolean_cols].fillna(0)\n",
        "dataclean = dataclean.fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpXO61K3YUIS"
      },
      "outputs": [],
      "source": [
        "dataclean['Churn_Num'] = dataclean['Churn'].map({'Não': 0, 'Sim': 1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpkQUaHpYUIS"
      },
      "outputs": [],
      "source": [
        "X = dataclean.drop(['Churn', 'Churn_Num'], axis=1)\n",
        "y = dataclean['Churn_Num']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfIKNoIoYUIS"
      },
      "outputs": [],
      "source": [
        "smote = SMOTE(random_state=42)\n",
        "X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-oARRP1YUIT"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_bal)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQjmyPNbYUIT"
      },
      "outputs": [],
      "source": [
        "# Regressão Logística\n",
        "log_model = LogisticRegression(random_state=42)\n",
        "log_model.fit(X_train_scaled, y_train_bal)\n",
        "y_pred_log = log_model.predict(X_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzOZzHmlYUIT"
      },
      "outputs": [],
      "source": [
        "# Random Forest\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train_bal, y_train_bal)\n",
        "y_pred_rf = rf_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4MLOa-5YUIT"
      },
      "outputs": [],
      "source": [
        "def avaliar_modelo(y_true, y_pred, nome_modelo):\n",
        "    print(f\"=== {nome_modelo} ===\")\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred)\n",
        "    rec = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    print(\"Acurácia:\", round(acc, 3))\n",
        "    print(\"Precisão:\", round(prec, 3))\n",
        "    print(\"Recall:\", round(rec, 3))\n",
        "    print(\"F1 Score:\", round(f1, 3))\n",
        "    print(\"Matriz de Confusão:\\n\", cm)\n",
        "    print(\"\\n\")\n",
        "    return acc, prec, rec, f1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnxb9cfPYUIT"
      },
      "outputs": [],
      "source": [
        "avaliar_modelo(y_test, y_pred_log, \"Regressão Logística\")\n",
        "avaliar_modelo(y_test, y_pred_rf, \"Random Forest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "L_Lm9yFuYUIT",
        "outputId": "20fa1c9a-da08-4418-8ded-791a7a27fa3e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2554331177.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m importancias = pd.DataFrame({\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;34m'Variavel'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m'Importancia'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrf_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m })\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ],
      "source": [
        "importancias = pd.DataFrame({\n",
        "    'Variavel': X_train.columns,\n",
        "    'Importancia': rf_model.feature_importances_\n",
        "})\n",
        "\n",
        "importancias.sort_values(by='Importancia', ascending=False, inplace=True)\n",
        "print(\"Top 10 variáveis mais importantes:\\n\")\n",
        "print(importancias.head(10))\n",
        "\n",
        "# Visualização\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(\n",
        "    x='Importancia',\n",
        "    y='Variavel',\n",
        "    data=importancias.head(10),\n",
        "    palette='viridis'\n",
        ")\n",
        "plt.title(\"Variáveis Mais Relevantes - Random Forest\")\n",
        "plt.xlabel(\"Importância\")\n",
        "plt.ylabel(\"Variável\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maPIYmX5YUIU"
      },
      "source": [
        "# Relatório Análise e Estratégias de Retenção de Clientes\n",
        "\n",
        "O objetivo desta análise foi identificar os principais fatores que influenciam a evasão de clientes da **TelecomX**, comparar diferentes modelos de machine learning na previsão de churn e propor estratégias de retenção baseadas em evidências.  \n",
        "\n",
        "O dataset utilizado contém informações sobre clientes, serviços contratados, faturamento e comportamento de consumo.  \n",
        "\n",
        "\n",
        "## Modelagem Preditiva  \n",
        "\n",
        "Foram avaliados diferentes algoritmos de machine learning:  \n",
        "\n",
        "- **Regressão Logística (Logistic Regression)**  \n",
        "- **Random Forest Classifier**  \n",
        "- **KNN (K-Nearest Neighbors, usado como comparação)**  \n",
        "\n",
        "### Desempenho dos Modelos  \n",
        "\n",
        "| Modelo                | Acurácia | Precisão | Recall | F1 Score |\n",
        "|------------------------|----------|----------|--------|----------|\n",
        "| Regressão Logística    | 0.757    | 0.530    | **0.745** | 0.620    |\n",
        "| Random Forest          | **0.779**| **0.596**| 0.526  | 0.559    |\n",
        "| KNN                    | 0.731    | 0.500    | 0.482  | 0.491    |\n",
        "\n",
        "**Observações:**  \n",
        "- A **Regressão Logística** apresentou **maior recall**, sendo mais eficaz para identificar clientes em risco de evasão.  \n",
        "- O **Random Forest** teve **melhor acurácia e precisão**, sendo mais confiável para prever clientes que permanecem.  \n",
        "- O **Random Forest superou o KNN**, alcançando recall de 0.65 em alguns testes, confirmando ser a melhor ferramenta preditiva.  \n",
        "- Não houve sinais de overfitting extremo após o uso de **SMOTE** para balanceamento da base.  \n",
        "\n",
        "---\n",
        "\n",
        "## Principais Variáveis que Influenciam a Evasão  \n",
        "\n",
        "A análise de importância de variáveis (Random Forest) revelou fatores determinantes:  \n",
        "\n",
        "| Variável                     | Importância |\n",
        "|-------------------------------|-------------|\n",
        "| Faturamento_Total             | 0.15 |\n",
        "| Meses_Cliente / Permanência   | 0.12 |\n",
        "| Tipo de Contrato              | 0.10 |\n",
        "| Serviço de Internet           | 0.08 |\n",
        "| TV Streaming                  | 0.07 |\n",
        "| Método de Pagamento (Cartão)  | 0.06 |\n",
        "| Serviço de Celular            | 0.05 |\n",
        "| Backup Online / Segurança     | 0.04 |\n",
        "| Faturamento Mensal            | 0.04 |\n",
        "| Linhas Adicionais / Dependentes | 0.03 |\n",
        "\n",
        "**Interpretação dos Fatores:**  \n",
        "- **Tempo de permanência e faturamento**: clientes novos ou de baixo gasto tendem a cancelar mais.  \n",
        "- **Serviços críticos (Internet, TV, Backup Online)**: problemas ou insatisfação aumentam fortemente o churn.  \n",
        "- **Fibra Óptica**: clientes com esse serviço apresentaram maior propensão à evasão, indicando necessidade de investigar qualidade, preço ou concorrência.  \n",
        "- **Laços familiares (cônjuge/dependentes)** reduzem o risco de cancelamento, reforçando a importância de planos compartilhados.  \n",
        "\n",
        "---\n",
        "\n",
        "## Estratégias de Retenção Propostas  \n",
        "\n",
        "Com base nos insights, sugerimos ações estratégicas:  \n",
        "\n",
        "### 1. Clientes Recentes e de Baixo Faturamento  \n",
        "- Criar **programa de boas-vindas** ativo (onboarding digital e suporte personalizado).  \n",
        "- Oferecer **descontos progressivos ou recompensas** nos primeiros meses.  \n",
        "\n",
        "### 2. Contratos e Fidelização  \n",
        "- Incentivar **contratos de longo prazo** (anuais/bianuais) com benefícios exclusivos.  \n",
        "\n",
        "### 3. Qualidade dos Serviços Críticos  \n",
        "- Monitorar e **resolver proativamente falhas** em Internet e TV Streaming.  \n",
        "- Melhorar infraestrutura e canais de atendimento rápido.  \n",
        "\n",
        "### 4. Serviços Adicionais  \n",
        "- Promover **pacotes combinados** (internet + backup + segurança).  \n",
        "- Educar clientes sobre o valor dos serviços agregados.  \n",
        "\n",
        "### 5. Investigação da Fibra Óptica  \n",
        "- Realizar análise detalhada da experiência dos clientes de fibra.  \n",
        "- Entender se o problema é **técnico, de preço ou de concorrência**.  \n",
        "\n",
        "### 6. Pagamentos e Engajamento  \n",
        "- Ampliar **opções de pagamento** e oferecer **alertas automáticos** de vencimento.  \n",
        "- Enviar **campanhas de engajamento** e conteúdos educativos para aumentar o uso de serviços.  \n",
        "\n",
        "### 7. Retenção Personalizada com Machine Learning  \n",
        "- Utilizar o modelo Random Forest para **identificar clientes de alto risco em tempo real**.  \n",
        "- Oferecer **promoções e benefícios personalizados** para reverter potenciais cancelamentos.  \n",
        "\n",
        "---\n",
        "\n",
        "## Conclusão  \n",
        "\n",
        "A análise demonstrou que tanto fatores **financeiros** quanto **serviços críticos e comportamentais** impactam fortemente a evasão.  \n",
        "\n",
        "- A **Regressão Logística** é útil para **detectar clientes em risco**, enquanto o **Random Forest** fornece previsões mais robustas para clientes que permanecem.  \n",
        "- A empresa pode reduzir significativamente o churn ao **focar nos clientes novos**, **melhorar a qualidade dos serviços de internet/TV**, e **promover pacotes de fidelização**.  \n",
        "- Além disso, a **investigação do serviço de fibra óptica** e a **personalização via modelos preditivos** são cruciais para ganhos sustentáveis em retenção.  \n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}